{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2688ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow tracking\n",
    "import mlflow\n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bebb9679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml libraries\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.saving import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae85cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "parameters = {\n",
    "    'learning_rate':0.01,\n",
    "    'momentum':0.1,\n",
    "    'beta1':0.5,\n",
    "    'beta2':0.5,\n",
    "    'epochs':20,\n",
    "    'batch_size':10,\n",
    "    'loss':'sparse_categorical_crossentropy'\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0127da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train and test data from mnist dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28, 28)\n",
    "x_test = x_test.reshape(10000, 28, 28)\n",
    "\n",
    "x_train, x_test = x_train/225, x_test/225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba2f8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84170 (328.79 KB)\n",
      "Trainable params: 84170 (328.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model body\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e73529ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading best modell of the 3 experiments done before\n",
    "model3 = load_model('sequentialBEST3.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d024a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of loss, metrics, optimizer, etc\n",
    "SGDM = SGD(learning_rate=parameters['learning_rate'], momentum=parameters['momentum'])\n",
    "\n",
    "# configuring the checkpoints to obtain the best model after resuming training on loaded model 'model3'\n",
    "checkpoint = ModelCheckpoint('best', save_best_only=True, monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(optimizer=SGDM, loss=parameters['loss'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d38263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/25 20:55:09 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '317780c28fc844e3b049de6c08d267e3', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/6000 [..............................] - ETA: 1:20:28 - loss: 6.2820e-04 - accuracy: 1.0000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0030s). Check your callbacks.\n",
      "5999/6000 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9988\n",
      "Epoch 1: val_loss improved from inf to 0.08685, saving model to best\n",
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 21s 3ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.0868 - val_accuracy: 0.9781\n",
      "Epoch 2/20\n",
      "5996/6000 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9990\n",
      "Epoch 2: val_loss improved from 0.08685 to 0.08553, saving model to best\n",
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.0855 - val_accuracy: 0.9777\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9993\n",
      "Epoch 3: val_loss improved from 0.08553 to 0.08358, saving model to best\n",
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 0.0836 - val_accuracy: 0.9782\n",
      "Epoch 4/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9995\n",
      "Epoch 4: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.0848 - val_accuracy: 0.9779\n",
      "Epoch 5/20\n",
      "5983/6000 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9995\n",
      "Epoch 5: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.0861 - val_accuracy: 0.9782\n",
      "Epoch 6/20\n",
      "5983/6000 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9996\n",
      "Epoch 6: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0855 - val_accuracy: 0.9789\n",
      "Epoch 7/20\n",
      "5998/6000 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9995\n",
      "Epoch 7: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0852 - val_accuracy: 0.9785\n",
      "Epoch 8/20\n",
      "5995/6000 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9997\n",
      "Epoch 8: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.0863 - val_accuracy: 0.9784\n",
      "Epoch 9/20\n",
      "5991/6000 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9998\n",
      "Epoch 9: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.0854 - val_accuracy: 0.9791\n",
      "Epoch 10/20\n",
      "5987/6000 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9998\n",
      "Epoch 10: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 20s 3ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.0871 - val_accuracy: 0.9789\n",
      "Epoch 11/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9998\n",
      "Epoch 11: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0869 - val_accuracy: 0.9785\n",
      "Epoch 12/20\n",
      "5981/6000 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9999\n",
      "Epoch 12: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0872 - val_accuracy: 0.9787\n",
      "Epoch 13/20\n",
      "5989/6000 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9999\n",
      "Epoch 13: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0876 - val_accuracy: 0.9791\n",
      "Epoch 14/20\n",
      "5990/6000 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9999\n",
      "Epoch 14: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0876 - val_accuracy: 0.9783\n",
      "Epoch 15/20\n",
      "5991/6000 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9999\n",
      "Epoch 15: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0873 - val_accuracy: 0.9787\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9999\n",
      "Epoch 16: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0880 - val_accuracy: 0.9784\n",
      "Epoch 17/20\n",
      "5993/6000 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9999\n",
      "Epoch 17: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0889 - val_accuracy: 0.9786\n",
      "Epoch 18/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9999\n",
      "Epoch 18: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0894 - val_accuracy: 0.9787\n",
      "Epoch 19/20\n",
      "5993/6000 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9999\n",
      "Epoch 19: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0895 - val_accuracy: 0.9785\n",
      "Epoch 20/20\n",
      "5990/6000 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9999\n",
      "Epoch 20: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0899 - val_accuracy: 0.9788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/25 21:01:22 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: tuple index out of range\n",
      "2023/09/25 21:01:22 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jtole\\AppData\\Local\\Temp\\tmpka3m4ia0\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jtole\\AppData\\Local\\Temp\\tmpka3m4ia0\\model\\data\\model\\assets\n",
      "2023/09/25 21:01:38 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25102166050>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training loaded model 'model3'\n",
    "model3.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=parameters['batch_size'], \n",
    "          epochs=parameters['epochs'], callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75ec304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0899 - accuracy: 0.9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08994003385305405, 0.9787999987602234]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation of loaded model\n",
    "model3.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e03d109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84170 (328.79 KB)\n",
      "Trainable params: 84170 (328.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "890db959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78500 (306.64 KB)\n",
      "Trainable params: 78500 (306.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.pop()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2a1048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84170 (328.79 KB)\n",
      "Trainable params: 84170 (328.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x27136efd750>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.add(Dense(50, activation='relu', kernel_regularizer='l2'))\n",
    "model3.add(Dense(10, activation='tanh'))\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "model3.summary()\n",
    "\n",
    "# loading to the model state where weights were the best, it is before detecting overfitting\n",
    "model3.load_weights('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "576bb91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/25 21:53:50 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd63de22b82cd4d76b5213e046e411178', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/6000 [..............................] - ETA: 1:20:49 - loss: 1.1531 - accuracy: 1.0000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.\n",
      "5997/6000 [============================>.] - ETA: 0s - loss: 0.4239 - accuracy: 0.9973\n",
      "Epoch 1: val_loss improved from inf to 0.18390, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 21s 3ms/step - loss: 0.4238 - accuracy: 0.9973 - val_loss: 0.1839 - val_accuracy: 0.9749\n",
      "Epoch 2/20\n",
      "5986/6000 [============================>.] - ETA: 0s - loss: 0.1087 - accuracy: 0.9872\n",
      "Epoch 2: val_loss improved from 0.18390 to 0.13059, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.1087 - accuracy: 0.9872 - val_loss: 0.1306 - val_accuracy: 0.9749\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9851\n",
      "Epoch 3: val_loss did not improve from 0.13059\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0933 - accuracy: 0.9851 - val_loss: 0.1363 - val_accuracy: 0.9720\n",
      "Epoch 4/20\n",
      "5992/6000 [============================>.] - ETA: 0s - loss: 0.0881 - accuracy: 0.9855\n",
      "Epoch 4: val_loss did not improve from 0.13059\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0882 - accuracy: 0.9855 - val_loss: 0.1387 - val_accuracy: 0.9692\n",
      "Epoch 5/20\n",
      "5982/6000 [============================>.] - ETA: 0s - loss: 0.0846 - accuracy: 0.9856\n",
      "Epoch 5: val_loss improved from 0.13059 to 0.12035, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0846 - accuracy: 0.9856 - val_loss: 0.1204 - val_accuracy: 0.9737\n",
      "Epoch 6/20\n",
      "5990/6000 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 0.9871\n",
      "Epoch 6: val_loss did not improve from 0.12035\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0791 - accuracy: 0.9871 - val_loss: 0.1244 - val_accuracy: 0.9730\n",
      "Epoch 7/20\n",
      "5992/6000 [============================>.] - ETA: 0s - loss: 0.0786 - accuracy: 0.9863\n",
      "Epoch 7: val_loss improved from 0.12035 to 0.11848, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0786 - accuracy: 0.9863 - val_loss: 0.1185 - val_accuracy: 0.9746\n",
      "Epoch 8/20\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9874\n",
      "Epoch 8: val_loss did not improve from 0.11848\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0751 - accuracy: 0.9874 - val_loss: 0.1395 - val_accuracy: 0.9680\n",
      "Epoch 9/20\n",
      "5986/6000 [============================>.] - ETA: 0s - loss: 0.0718 - accuracy: 0.9881\n",
      "Epoch 9: val_loss improved from 0.11848 to 0.11481, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0718 - accuracy: 0.9881 - val_loss: 0.1148 - val_accuracy: 0.9753\n",
      "Epoch 10/20\n",
      "5983/6000 [============================>.] - ETA: 0s - loss: 0.0704 - accuracy: 0.9880\n",
      "Epoch 10: val_loss did not improve from 0.11481\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0704 - accuracy: 0.9880 - val_loss: 0.1200 - val_accuracy: 0.9736\n",
      "Epoch 11/20\n",
      "5990/6000 [============================>.] - ETA: 0s - loss: 0.0673 - accuracy: 0.9889\n",
      "Epoch 11: val_loss did not improve from 0.11481\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0673 - accuracy: 0.9889 - val_loss: 0.1217 - val_accuracy: 0.9738\n",
      "Epoch 12/20\n",
      "5990/6000 [============================>.] - ETA: 0s - loss: 0.0662 - accuracy: 0.9891\n",
      "Epoch 12: val_loss did not improve from 0.11481\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0662 - accuracy: 0.9891 - val_loss: 0.1153 - val_accuracy: 0.9757\n",
      "Epoch 13/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 0.9897\n",
      "Epoch 13: val_loss did not improve from 0.11481\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0646 - accuracy: 0.9897 - val_loss: 0.1197 - val_accuracy: 0.9738\n",
      "Epoch 14/20\n",
      "5984/6000 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 0.9893\n",
      "Epoch 14: val_loss improved from 0.11481 to 0.11104, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0638 - accuracy: 0.9893 - val_loss: 0.1110 - val_accuracy: 0.9761\n",
      "Epoch 15/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.0607 - accuracy: 0.9902\n",
      "Epoch 15: val_loss did not improve from 0.11104\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0607 - accuracy: 0.9902 - val_loss: 0.1219 - val_accuracy: 0.9736\n",
      "Epoch 16/20\n",
      "5986/6000 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9915\n",
      "Epoch 16: val_loss improved from 0.11104 to 0.10334, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0580 - accuracy: 0.9915 - val_loss: 0.1033 - val_accuracy: 0.9767\n",
      "Epoch 17/20\n",
      "5993/6000 [============================>.] - ETA: 0s - loss: 0.0574 - accuracy: 0.9910\n",
      "Epoch 17: val_loss did not improve from 0.10334\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0574 - accuracy: 0.9910 - val_loss: 0.1108 - val_accuracy: 0.9751\n",
      "Epoch 18/20\n",
      "5993/6000 [============================>.] - ETA: 0s - loss: 0.0562 - accuracy: 0.9913\n",
      "Epoch 18: val_loss did not improve from 0.10334\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0562 - accuracy: 0.9913 - val_loss: 0.1255 - val_accuracy: 0.9712\n",
      "Epoch 19/20\n",
      "5982/6000 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 0.9912\n",
      "Epoch 19: val_loss did not improve from 0.10334\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0554 - accuracy: 0.9911 - val_loss: 0.1319 - val_accuracy: 0.9717\n",
      "Epoch 20/20\n",
      "5985/6000 [============================>.] - ETA: 0s - loss: 0.0540 - accuracy: 0.9915\n",
      "Epoch 20: val_loss did not improve from 0.10334\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0540 - accuracy: 0.9915 - val_loss: 0.1137 - val_accuracy: 0.9770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/25 22:00:06 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: tuple index out of range\n",
      "2023/09/25 22:00:06 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jtole\\AppData\\Local\\Temp\\tmpz58i5kqt\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jtole\\AppData\\Local\\Temp\\tmpz58i5kqt\\model\\data\\model\\assets\n",
      "2023/09/25 22:00:20 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x27137df3bb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_L2 = ModelCheckpoint('best_L2', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "model3.compile(optimizer=SGDM, loss=parameters['loss'], metrics=['accuracy'])\n",
    "\n",
    "model3.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=parameters['batch_size'], \n",
    "          epochs=parameters['epochs'], callbacks=[checkpoint_L2], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9356567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1137 - accuracy: 0.9770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.113724485039711, 0.9769999980926514]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation of loaded model\n",
    "model3.evaluate(x_test, y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
