{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2688ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow tracking\n",
    "import mlflow\n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bebb9679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml libraries\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.saving import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae85cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "parameters = {\n",
    "    'learning_rate':0.01,\n",
    "    'momentum':0.1,\n",
    "    'beta1':0.5,\n",
    "    'beta2':0.5,\n",
    "    'epochs':20,\n",
    "    'batch_size':10,\n",
    "    'loss':'sparse_categorical_crossentropy'\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0127da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train and test data from mnist dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28, 28)\n",
    "x_test = x_test.reshape(10000, 28, 28)\n",
    "\n",
    "x_train, x_test = x_train/225, x_test/225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba2f8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84170 (328.79 KB)\n",
      "Trainable params: 84170 (328.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model body\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f82d7e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading best modell of the 3 experiments done before\n",
    "model3 = load_model('sequentialBEST3.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d024a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of loss, metrics, optimizer, etc\n",
    "SGDM = SGD(learning_rate=parameters['learning_rate'], momentum=parameters['momentum'])\n",
    "\n",
    "# configuring the checkpoints to obtain the best model after resuming training on loaded model 'model3'\n",
    "checkpoint = ModelCheckpoint('best', save_best_only=True, monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d13389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(optimizer=SGDM, loss=parameters['loss'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d38263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/25 20:55:09 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '317780c28fc844e3b049de6c08d267e3', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/6000 [..............................] - ETA: 1:20:28 - loss: 6.2820e-04 - accuracy: 1.0000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0030s). Check your callbacks.\n",
      "5999/6000 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9988\n",
      "Epoch 1: val_loss improved from inf to 0.08685, saving model to best\n",
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 21s 3ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.0868 - val_accuracy: 0.9781\n",
      "Epoch 2/20\n",
      "5996/6000 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9990\n",
      "Epoch 2: val_loss improved from 0.08685 to 0.08553, saving model to best\n",
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.0855 - val_accuracy: 0.9777\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9993\n",
      "Epoch 3: val_loss improved from 0.08553 to 0.08358, saving model to best\n",
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 0.0836 - val_accuracy: 0.9782\n",
      "Epoch 4/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9995\n",
      "Epoch 4: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.0848 - val_accuracy: 0.9779\n",
      "Epoch 5/20\n",
      "5983/6000 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9995\n",
      "Epoch 5: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.0861 - val_accuracy: 0.9782\n",
      "Epoch 6/20\n",
      "5983/6000 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9996\n",
      "Epoch 6: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0855 - val_accuracy: 0.9789\n",
      "Epoch 7/20\n",
      "5998/6000 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9995\n",
      "Epoch 7: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0852 - val_accuracy: 0.9785\n",
      "Epoch 8/20\n",
      "5995/6000 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9997\n",
      "Epoch 8: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.0863 - val_accuracy: 0.9784\n",
      "Epoch 9/20\n",
      "5991/6000 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9998\n",
      "Epoch 9: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.0854 - val_accuracy: 0.9791\n",
      "Epoch 10/20\n",
      "5987/6000 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9998\n",
      "Epoch 10: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 20s 3ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.0871 - val_accuracy: 0.9789\n",
      "Epoch 11/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9998\n",
      "Epoch 11: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0869 - val_accuracy: 0.9785\n",
      "Epoch 12/20\n",
      "5981/6000 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9999\n",
      "Epoch 12: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0872 - val_accuracy: 0.9787\n",
      "Epoch 13/20\n",
      "5989/6000 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9999\n",
      "Epoch 13: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0876 - val_accuracy: 0.9791\n",
      "Epoch 14/20\n",
      "5990/6000 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9999\n",
      "Epoch 14: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0876 - val_accuracy: 0.9783\n",
      "Epoch 15/20\n",
      "5991/6000 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9999\n",
      "Epoch 15: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0873 - val_accuracy: 0.9787\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9999\n",
      "Epoch 16: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0880 - val_accuracy: 0.9784\n",
      "Epoch 17/20\n",
      "5993/6000 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9999\n",
      "Epoch 17: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0889 - val_accuracy: 0.9786\n",
      "Epoch 18/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9999\n",
      "Epoch 18: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0894 - val_accuracy: 0.9787\n",
      "Epoch 19/20\n",
      "5993/6000 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9999\n",
      "Epoch 19: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0895 - val_accuracy: 0.9785\n",
      "Epoch 20/20\n",
      "5990/6000 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9999\n",
      "Epoch 20: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0899 - val_accuracy: 0.9788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/25 21:01:22 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: tuple index out of range\n",
      "2023/09/25 21:01:22 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jtole\\AppData\\Local\\Temp\\tmpka3m4ia0\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jtole\\AppData\\Local\\Temp\\tmpka3m4ia0\\model\\data\\model\\assets\n",
      "2023/09/25 21:01:38 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25102166050>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training loaded model 'model3'\n",
    "model3.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=parameters['batch_size'], \n",
    "          epochs=parameters['epochs'], callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75ec304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0899 - accuracy: 0.9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08994003385305405, 0.9787999987602234]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation of loaded model\n",
    "model3.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a34a8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84170 (328.79 KB)\n",
      "Trainable params: 84170 (328.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c70f94b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78500 (306.64 KB)\n",
      "Trainable params: 78500 (306.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.pop()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2011995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84170 (328.79 KB)\n",
      "Trainable params: 84170 (328.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x11272ac7cd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.add(Dense(50, activation='relu', kernel_regularizer='l1_l2'))\n",
    "model3.add(Dense(10, activation='tanh'))\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "model3.summary()\n",
    "\n",
    "# loading to the model state where weights were the best, it is before detecting overfitting\n",
    "model3.load_weights('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3bd7fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/25 22:46:04 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'aaf07fbec9314f98953f5cbdf774afed', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/6000 [..............................] - ETA: 1:26:30 - loss: 7.4546 - accuracy: 1.0000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0054s). Check your callbacks.\n",
      "5997/6000 [============================>.] - ETA: 0s - loss: 1.1284 - accuracy: 0.9613\n",
      "Epoch 1: val_loss improved from inf to 0.52841, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 21s 3ms/step - loss: 1.1281 - accuracy: 0.9613 - val_loss: 0.5284 - val_accuracy: 0.9190\n",
      "Epoch 2/20\n",
      "5993/6000 [============================>.] - ETA: 0s - loss: 0.3687 - accuracy: 0.9562\n",
      "Epoch 2: val_loss improved from 0.52841 to 0.35307, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.3687 - accuracy: 0.9562 - val_loss: 0.3531 - val_accuracy: 0.9555\n",
      "Epoch 3/20\n",
      "5989/6000 [============================>.] - ETA: 0s - loss: 0.3201 - accuracy: 0.9599\n",
      "Epoch 3: val_loss did not improve from 0.35307\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.3201 - accuracy: 0.9599 - val_loss: 0.4057 - val_accuracy: 0.9261\n",
      "Epoch 4/20\n",
      "5994/6000 [============================>.] - ETA: 0s - loss: 0.2959 - accuracy: 0.9629\n",
      "Epoch 4: val_loss improved from 0.35307 to 0.28114, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.2958 - accuracy: 0.9629 - val_loss: 0.2811 - val_accuracy: 0.9617\n",
      "Epoch 5/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.2836 - accuracy: 0.9631\n",
      "Epoch 5: val_loss improved from 0.28114 to 0.26862, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.2835 - accuracy: 0.9632 - val_loss: 0.2686 - val_accuracy: 0.9665\n",
      "Epoch 6/20\n",
      "5997/6000 [============================>.] - ETA: 0s - loss: 0.2727 - accuracy: 0.9653\n",
      "Epoch 6: val_loss did not improve from 0.26862\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.2728 - accuracy: 0.9653 - val_loss: 0.2788 - val_accuracy: 0.9610\n",
      "Epoch 7/20\n",
      "5990/6000 [============================>.] - ETA: 0s - loss: 0.2600 - accuracy: 0.9665\n",
      "Epoch 7: val_loss improved from 0.26862 to 0.26842, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.2600 - accuracy: 0.9665 - val_loss: 0.2684 - val_accuracy: 0.9610\n",
      "Epoch 8/20\n",
      "5982/6000 [============================>.] - ETA: 0s - loss: 0.2506 - accuracy: 0.9676\n",
      "Epoch 8: val_loss did not improve from 0.26842\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.2511 - accuracy: 0.9675 - val_loss: 0.3005 - val_accuracy: 0.9552\n",
      "Epoch 9/20\n",
      "5999/6000 [============================>.] - ETA: 0s - loss: 0.2480 - accuracy: 0.9679\n",
      "Epoch 9: val_loss improved from 0.26842 to 0.25386, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.2480 - accuracy: 0.9679 - val_loss: 0.2539 - val_accuracy: 0.9648\n",
      "Epoch 10/20\n",
      "5991/6000 [============================>.] - ETA: 0s - loss: 0.2381 - accuracy: 0.9698\n",
      "Epoch 10: val_loss did not improve from 0.25386\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.2381 - accuracy: 0.9698 - val_loss: 0.2646 - val_accuracy: 0.9595\n",
      "Epoch 11/20\n",
      "5987/6000 [============================>.] - ETA: 0s - loss: 0.2351 - accuracy: 0.9694\n",
      "Epoch 11: val_loss did not improve from 0.25386\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.2351 - accuracy: 0.9694 - val_loss: 0.2667 - val_accuracy: 0.9611\n",
      "Epoch 12/20\n",
      "5989/6000 [============================>.] - ETA: 0s - loss: 0.2305 - accuracy: 0.9705\n",
      "Epoch 12: val_loss improved from 0.25386 to 0.24389, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.2304 - accuracy: 0.9705 - val_loss: 0.2439 - val_accuracy: 0.9659\n",
      "Epoch 13/20\n",
      "5991/6000 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.9705\n",
      "Epoch 13: val_loss did not improve from 0.24389\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.2289 - accuracy: 0.9705 - val_loss: 0.2579 - val_accuracy: 0.9634\n",
      "Epoch 14/20\n",
      "5987/6000 [============================>.] - ETA: 0s - loss: 0.2273 - accuracy: 0.9712\n",
      "Epoch 14: val_loss did not improve from 0.24389\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.2273 - accuracy: 0.9712 - val_loss: 0.2467 - val_accuracy: 0.9635\n",
      "Epoch 15/20\n",
      "5985/6000 [============================>.] - ETA: 0s - loss: 0.2203 - accuracy: 0.9724\n",
      "Epoch 15: val_loss did not improve from 0.24389\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.2203 - accuracy: 0.9724 - val_loss: 0.2520 - val_accuracy: 0.9636\n",
      "Epoch 16/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9730\n",
      "Epoch 16: val_loss did not improve from 0.24389\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.2170 - accuracy: 0.9730 - val_loss: 0.2478 - val_accuracy: 0.9678\n",
      "Epoch 17/20\n",
      "5996/6000 [============================>.] - ETA: 0s - loss: 0.2149 - accuracy: 0.9731\n",
      "Epoch 17: val_loss did not improve from 0.24389\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.2149 - accuracy: 0.9731 - val_loss: 0.2470 - val_accuracy: 0.9616\n",
      "Epoch 18/20\n",
      "5991/6000 [============================>.] - ETA: 0s - loss: 0.2142 - accuracy: 0.9736\n",
      "Epoch 18: val_loss did not improve from 0.24389\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.2142 - accuracy: 0.9736 - val_loss: 0.2675 - val_accuracy: 0.9522\n",
      "Epoch 19/20\n",
      "5984/6000 [============================>.] - ETA: 0s - loss: 0.2069 - accuracy: 0.9743\n",
      "Epoch 19: val_loss improved from 0.24389 to 0.22823, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.2068 - accuracy: 0.9744 - val_loss: 0.2282 - val_accuracy: 0.9674\n",
      "Epoch 20/20\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9747\n",
      "Epoch 20: val_loss improved from 0.22823 to 0.21848, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.2063 - accuracy: 0.9747 - val_loss: 0.2185 - val_accuracy: 0.9664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/25 22:52:19 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: tuple index out of range\n",
      "2023/09/25 22:52:19 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jtole\\AppData\\Local\\Temp\\tmp7p281dsh\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jtole\\AppData\\Local\\Temp\\tmp7p281dsh\\model\\data\\model\\assets\n",
      "2023/09/25 22:52:33 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x112167246d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_L2 = ModelCheckpoint('best_L2', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "model3.compile(optimizer=SGDM, loss=parameters['loss'], metrics=['accuracy'])\n",
    "\n",
    "model3.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=parameters['batch_size'], \n",
    "          epochs=parameters['epochs'], callbacks=[checkpoint_L2], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cf90dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2185 - accuracy: 0.9664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21848401427268982, 0.9664000272750854]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation of loaded model\n",
    "model3.evaluate(x_test, y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
