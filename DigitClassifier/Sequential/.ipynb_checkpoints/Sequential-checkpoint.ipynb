{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2688ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow tracking\n",
    "import mlflow\n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bebb9679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml libraries\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.saving import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae85cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "parameters = {\n",
    "    'learning_rate':0.01,\n",
    "    'momentum':0.1,\n",
    "    'beta1':0.5,\n",
    "    'beta2':0.5,\n",
    "    'epochs':20,\n",
    "    'batch_size':10,\n",
    "    'loss':'sparse_categorical_crossentropy'\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0127da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train and test data from mnist dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28, 28)\n",
    "x_test = x_test.reshape(10000, 28, 28)\n",
    "\n",
    "x_train, x_test = x_train/225, x_test/225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba2f8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84170 (328.79 KB)\n",
      "Trainable params: 84170 (328.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model body\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4559c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading best modell of the 3 experiments done before\n",
    "model3 = load_model('sequentialBEST3.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d024a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of loss, metrics, optimizer, etc\n",
    "SGDM = SGD(learning_rate=parameters['learning_rate'], momentum=parameters['momentum'])\n",
    "\n",
    "# configuring the checkpoints to obtain the best model after resuming training on loaded model 'model3'\n",
    "checkpoint = ModelCheckpoint('best', save_best_only=True, monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ce202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(optimizer=SGDM, loss=parameters['loss'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d38263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/25 20:55:09 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '317780c28fc844e3b049de6c08d267e3', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/6000 [..............................] - ETA: 1:20:28 - loss: 6.2820e-04 - accuracy: 1.0000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0030s). Check your callbacks.\n",
      "5999/6000 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9988\n",
      "Epoch 1: val_loss improved from inf to 0.08685, saving model to best\n",
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 21s 3ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.0868 - val_accuracy: 0.9781\n",
      "Epoch 2/20\n",
      "5996/6000 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9990\n",
      "Epoch 2: val_loss improved from 0.08685 to 0.08553, saving model to best\n",
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.0855 - val_accuracy: 0.9777\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9993\n",
      "Epoch 3: val_loss improved from 0.08553 to 0.08358, saving model to best\n",
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 0.0836 - val_accuracy: 0.9782\n",
      "Epoch 4/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9995\n",
      "Epoch 4: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.0848 - val_accuracy: 0.9779\n",
      "Epoch 5/20\n",
      "5983/6000 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9995\n",
      "Epoch 5: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.0861 - val_accuracy: 0.9782\n",
      "Epoch 6/20\n",
      "5983/6000 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9996\n",
      "Epoch 6: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0855 - val_accuracy: 0.9789\n",
      "Epoch 7/20\n",
      "5998/6000 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9995\n",
      "Epoch 7: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0852 - val_accuracy: 0.9785\n",
      "Epoch 8/20\n",
      "5995/6000 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9997\n",
      "Epoch 8: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.0863 - val_accuracy: 0.9784\n",
      "Epoch 9/20\n",
      "5991/6000 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9998\n",
      "Epoch 9: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.0854 - val_accuracy: 0.9791\n",
      "Epoch 10/20\n",
      "5987/6000 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9998\n",
      "Epoch 10: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 20s 3ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.0871 - val_accuracy: 0.9789\n",
      "Epoch 11/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9998\n",
      "Epoch 11: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0869 - val_accuracy: 0.9785\n",
      "Epoch 12/20\n",
      "5981/6000 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9999\n",
      "Epoch 12: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0872 - val_accuracy: 0.9787\n",
      "Epoch 13/20\n",
      "5989/6000 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9999\n",
      "Epoch 13: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0876 - val_accuracy: 0.9791\n",
      "Epoch 14/20\n",
      "5990/6000 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9999\n",
      "Epoch 14: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0876 - val_accuracy: 0.9783\n",
      "Epoch 15/20\n",
      "5991/6000 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9999\n",
      "Epoch 15: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0873 - val_accuracy: 0.9787\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9999\n",
      "Epoch 16: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0880 - val_accuracy: 0.9784\n",
      "Epoch 17/20\n",
      "5993/6000 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9999\n",
      "Epoch 17: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0889 - val_accuracy: 0.9786\n",
      "Epoch 18/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9999\n",
      "Epoch 18: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0894 - val_accuracy: 0.9787\n",
      "Epoch 19/20\n",
      "5993/6000 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9999\n",
      "Epoch 19: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0895 - val_accuracy: 0.9785\n",
      "Epoch 20/20\n",
      "5990/6000 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9999\n",
      "Epoch 20: val_loss did not improve from 0.08358\n",
      "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0899 - val_accuracy: 0.9788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/25 21:01:22 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: tuple index out of range\n",
      "2023/09/25 21:01:22 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jtole\\AppData\\Local\\Temp\\tmpka3m4ia0\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jtole\\AppData\\Local\\Temp\\tmpka3m4ia0\\model\\data\\model\\assets\n",
      "2023/09/25 21:01:38 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25102166050>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training loaded model 'model3'\n",
    "model3.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=parameters['batch_size'], \n",
    "          epochs=parameters['epochs'], callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75ec304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0899 - accuracy: 0.9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08994003385305405, 0.9787999987602234]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation of loaded model\n",
    "model3.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed9e843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84170 (328.79 KB)\n",
      "Trainable params: 84170 (328.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50f396f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78500 (306.64 KB)\n",
      "Trainable params: 78500 (306.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.pop()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4103c65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84170 (328.79 KB)\n",
      "Trainable params: 84170 (328.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loading to the model state where weights were the best, it is before detecting overfitting\n",
    "model3.load_weights('best')\n",
    "\n",
    "model3.add(Dense(50, activation='relu', kernel_regularizer='l1_l2'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(10, activation='tanh'))\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb7b2ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/25 23:14:35 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd2f4bd0106a94e4c88ed844d36c0e29c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/6000 [..............................] - ETA: 1:52:39 - loss: 7.9428 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0044s). Check your callbacks.\n",
      "5987/6000 [============================>.] - ETA: 0s - loss: 1.3097 - accuracy: 0.8605\n",
      "Epoch 1: val_loss improved from inf to 0.51404, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 26s 4ms/step - loss: 1.3082 - accuracy: 0.8606 - val_loss: 0.5140 - val_accuracy: 0.9378\n",
      "Epoch 2/20\n",
      "5998/6000 [============================>.] - ETA: 0s - loss: 0.5348 - accuracy: 0.9225\n",
      "Epoch 2: val_loss improved from 0.51404 to 0.44656, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 24s 4ms/step - loss: 0.5348 - accuracy: 0.9225 - val_loss: 0.4466 - val_accuracy: 0.9441\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.4722 - accuracy: 0.9331\n",
      "Epoch 3: val_loss improved from 0.44656 to 0.39596, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 24s 4ms/step - loss: 0.4722 - accuracy: 0.9331 - val_loss: 0.3960 - val_accuracy: 0.9506\n",
      "Epoch 4/20\n",
      "5995/6000 [============================>.] - ETA: 0s - loss: 0.4413 - accuracy: 0.9371\n",
      "Epoch 4: val_loss improved from 0.39596 to 0.39052, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 23s 4ms/step - loss: 0.4413 - accuracy: 0.9371 - val_loss: 0.3905 - val_accuracy: 0.9484\n",
      "Epoch 5/20\n",
      "5994/6000 [============================>.] - ETA: 0s - loss: 0.4181 - accuracy: 0.9409\n",
      "Epoch 5: val_loss improved from 0.39052 to 0.36855, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 24s 4ms/step - loss: 0.4181 - accuracy: 0.9409 - val_loss: 0.3685 - val_accuracy: 0.9554\n",
      "Epoch 6/20\n",
      "5990/6000 [============================>.] - ETA: 0s - loss: 0.4000 - accuracy: 0.9455\n",
      "Epoch 6: val_loss did not improve from 0.36855\n",
      "6000/6000 [==============================] - 22s 4ms/step - loss: 0.4002 - accuracy: 0.9455 - val_loss: 0.3772 - val_accuracy: 0.9499\n",
      "Epoch 7/20\n",
      "5997/6000 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.9466\n",
      "Epoch 7: val_loss did not improve from 0.36855\n",
      "6000/6000 [==============================] - 23s 4ms/step - loss: 0.3873 - accuracy: 0.9466 - val_loss: 0.3899 - val_accuracy: 0.9476\n",
      "Epoch 8/20\n",
      "5997/6000 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.9483\n",
      "Epoch 8: val_loss improved from 0.36855 to 0.33636, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 24s 4ms/step - loss: 0.3816 - accuracy: 0.9483 - val_loss: 0.3364 - val_accuracy: 0.9600\n",
      "Epoch 9/20\n",
      "5976/6000 [============================>.] - ETA: 0s - loss: 0.3739 - accuracy: 0.9501\n",
      "Epoch 9: val_loss did not improve from 0.33636\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.3737 - accuracy: 0.9501 - val_loss: 0.3604 - val_accuracy: 0.9545\n",
      "Epoch 10/20\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.3641 - accuracy: 0.9513\n",
      "Epoch 10: val_loss improved from 0.33636 to 0.33292, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.3641 - accuracy: 0.9513 - val_loss: 0.3329 - val_accuracy: 0.9615\n",
      "Epoch 11/20\n",
      "5987/6000 [============================>.] - ETA: 0s - loss: 0.3605 - accuracy: 0.9521\n",
      "Epoch 11: val_loss did not improve from 0.33292\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.3606 - accuracy: 0.9522 - val_loss: 0.3333 - val_accuracy: 0.9604\n",
      "Epoch 12/20\n",
      "5979/6000 [============================>.] - ETA: 0s - loss: 0.3534 - accuracy: 0.9534\n",
      "Epoch 12: val_loss did not improve from 0.33292\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.3535 - accuracy: 0.9534 - val_loss: 0.3862 - val_accuracy: 0.9285\n",
      "Epoch 13/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.3500 - accuracy: 0.9540\n",
      "Epoch 13: val_loss improved from 0.33292 to 0.32277, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 15s 2ms/step - loss: 0.3500 - accuracy: 0.9540 - val_loss: 0.3228 - val_accuracy: 0.9561\n",
      "Epoch 14/20\n",
      "5988/6000 [============================>.] - ETA: 0s - loss: 0.3465 - accuracy: 0.9554\n",
      "Epoch 14: val_loss did not improve from 0.32277\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.3467 - accuracy: 0.9553 - val_loss: 0.3475 - val_accuracy: 0.9590\n",
      "Epoch 15/20\n",
      "5990/6000 [============================>.] - ETA: 0s - loss: 0.3438 - accuracy: 0.9562\n",
      "Epoch 15: val_loss did not improve from 0.32277\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.3438 - accuracy: 0.9562 - val_loss: 0.3370 - val_accuracy: 0.9593\n",
      "Epoch 16/20\n",
      "5976/6000 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.9565\n",
      "Epoch 16: val_loss improved from 0.32277 to 0.31882, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.3401 - accuracy: 0.9566 - val_loss: 0.3188 - val_accuracy: 0.9643\n",
      "Epoch 17/20\n",
      "5993/6000 [============================>.] - ETA: 0s - loss: 0.3400 - accuracy: 0.9566\n",
      "Epoch 17: val_loss improved from 0.31882 to 0.31837, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.3399 - accuracy: 0.9567 - val_loss: 0.3184 - val_accuracy: 0.9633\n",
      "Epoch 18/20\n",
      "5977/6000 [============================>.] - ETA: 0s - loss: 0.3410 - accuracy: 0.9561\n",
      "Epoch 18: val_loss did not improve from 0.31837\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.3409 - accuracy: 0.9561 - val_loss: 0.3461 - val_accuracy: 0.9545\n",
      "Epoch 19/20\n",
      "5998/6000 [============================>.] - ETA: 0s - loss: 0.3373 - accuracy: 0.9564\n",
      "Epoch 19: val_loss did not improve from 0.31837\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.3372 - accuracy: 0.9564 - val_loss: 0.3424 - val_accuracy: 0.9582\n",
      "Epoch 20/20\n",
      "5983/6000 [============================>.] - ETA: 0s - loss: 0.3307 - accuracy: 0.9587\n",
      "Epoch 20: val_loss improved from 0.31837 to 0.31812, saving model to best_L2\n",
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_L2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.3308 - accuracy: 0.9587 - val_loss: 0.3181 - val_accuracy: 0.9594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/25 23:20:40 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: tuple index out of range\n",
      "2023/09/25 23:20:40 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jtole\\AppData\\Local\\Temp\\tmpi94n_5lb\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jtole\\AppData\\Local\\Temp\\tmpi94n_5lb\\model\\data\\model\\assets\n",
      "2023/09/25 23:20:49 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c334664310>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_L2 = ModelCheckpoint('best_L2', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "model3.compile(optimizer=SGDM, loss=parameters['loss'], metrics=['accuracy'])\n",
    "\n",
    "model3.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=parameters['batch_size'], \n",
    "          epochs=parameters['epochs'], callbacks=[checkpoint_L2], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5644bf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3181 - accuracy: 0.9594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3181154727935791, 0.9593999981880188]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation of loaded model\n",
    "model3.evaluate(x_test, y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
